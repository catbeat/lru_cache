/*  The state machine specifically for L1Cache, the following is the description
    which indicates that it uses MSI protocol */
machine(MachineType:L1Cache, "MSI Cache")
:Sequencer *sequencer;      // a piece of memory with slave port to receive message from others
 CacheMemory *cacheMemory;  // the cache memory stores the data and states
 bool send_evictions;       // used for out-of-order core when we need to evict an address so that we can operate on the load-store queue

 /* all the message data line are defined below */

 // the message buffer used for sending request to directory, the priority is 0(low)
 MessageBuffer *requestToDir, network="To", virtual_network="0", vnet_type="request";

 // the message buffer used for sending response to directory or other core's cache, the priority is 2(highest)
 MessageBuffer *responseToDirOrSibling, network="To", virtual_network="2", vnet_type="response";

 // the message buffer used for receive forward operation from directory, its priority should be 1 as it's usually activated by a previous request to directory
 MessageBuffer *forwardFromDir, network="from", virtual_network="1", vnet_type="forward";

 // the message buffer used for response sent from directory or other L1 cache, its priority is 2, too
 MessageBuffer *responseFromDirOrSibling, network="from", virtual_network="2", vnet_type="response";

 // repulsory member which gem5 transfer packet into ruby packet, used by sequencer
 MessageBuffer *mandatoryQueue;
{

    /* ------------------------------------------------------
        following part is the definition of cache entry states
        some of them is static states like I, M, some are midd-
        le/transforming states, followed by AccessPermission, 
        which indicates as its name.
    ---------------------------------------------------------*/
    state_declaration(State, desc="Cache entry states"){

        /* Invalid state */

        I,  AccessPermission:Invalid, desc="Not present/Invalid";

        IS_D, AccessPermission:Invalid, desc="from invalid to share, waiting for data";
        IM_AD, AccessPermission:Invalid, desc="from invalid to modify, waiting for acks and data, when that was M in another core's cache";
        IM_A, AccessPermission:Busy, desc="from invalid to modify, waiting  for acks";

        S, AccessPermission:Read_Only, desc="shared";

        SM_AD, AccessPermission:Read_Only, desc="from shared to modify, waiting for acks and data";
        SM_A, AccessPermission:Read_Only, desc="from shared to modify, waiting for acks";

        M, AccessPermission:Read_Write, desc="modified";

        MI_A, AccessPermission:Busy, desc="from modified to invalid, waiting for put ack";

        SI_A, AccessPermission:Busy, desc="from shared to invalid, waiting for put ack";

        II_A, AccessPermission:Invalid, desc="sent valid data before receiving put ack";
    }

    /*----------------------------------------------------------
        Event definition
    ----------------------------------------------------------*/

    enumeration(Event, desc="Cache events"){
        // from the processor or sequencer or mandatory queue
        Load,           desc="Load from processor";
        Store,          desc="Store from processor";

        Replacement,    desc="Triggered when find victim"

        FwdGetS,        desc="Directory send this to satisfy getS, it ask a cache to change M to S for response";
        FwdGetM,        desc="Directory send this to satisfy getM, it ask a cache to change M to I for response";
        Inv,            desc="Directory send this to invalidate a cache's shared tag";
        PutAck,         desc="Directory respond when we issue put, it avoids deadlock";

        DataDirNoAcks,  desc="Response of Data from Directory (ack = 0)";
        DataDirAcks,    desc="Response of Data from Directory (ack > 0)";

        DataOwner,      desc="Response of Data from Owner";
        InvAck,         desc="Invalidation ack after receiving Inv";

        LastInvAck,     desc="Triggered after the last ack is received"; 
    }

    structure(Entry, desc="Cache Entry", interface="AbstractCacheEntry"){
        State CacheState,   desc="the state of entry";
        DataBlock DataBlk,  desc="the block for data";
    }

    structure(TBE, desc="Transient buffer entry"){
        State TBEState,     desc="the state of block";
        DataBlock DataBlk,  desc="the block for data";
        int AckOutstanding, default=0, desc="Number of acks left to receive";
    }

    structure(TBETable, external="yes"){
        TBE lookup(Addr);
        void allocate(Addr);
        void deallocate(Addr);
        bool isPresent(Addr);
    }

    /* member function */

    TBETable TBEs, template="<L1Cache_TBE>", constructor="m_number_of_TBEs";

    Tick clockEdge();

    void set_cache_entry(AbstractCacheEntry a);
    void unset_cache_entry();
    void set_tbe(TBE b);
    void unset_tbe();

    MachineID mapAddressToMachine(Addr addr, MachineType mtype);

    Entry getCacheEntry(Addr address), return_by_pointer="yes" {
        return static_cast(Entry, "pointer", cacheMemory.lookup(address));
    }

    State getState(TBE tbe, Entry cache_entry, Addr addr){
        if (is_valid(tbe)){
            return tbe.TBEState;
        }
        else if (is_valid(cache_entry)){
            return cache_entry.CacheState;
        }
        else{
            return State:I;
        }
    }

    void setState(TBE tbe, Entry cache_entry, Addr addr, State state){
        if (is_valid(tbe)){
            tbe.TBEState := state;
        }

        if (is_valid(cache_entry)){
            cache_entry.CacheState := state;
        }
    }

    AccessPermission getAccessPermission(Addr addr){
        TBE tbe := TBEs[addr];

        // if the content is already in TBE( it's undergo changing), so the permission decide by the state of TBE entry
        if (is_valid(tbe)){
            return L1Cache_State_to_permission(tbe.TBEState);
        }

        Entry cache_entry := getCacheEntry(addr);

        // find it in cache and we get
        if (is_valid(cache_entry)){
            return L1Cache_State_to_permission(cache_entry.CacheState);
        }

        // Still in main memory
        return AccessPermission:NotPresent;
    }

    void setAccessPermission(Entry cache_entry, Addr addr, State, state){
        if (is_valid(cache_entry)){
            cache_entry.changePermission(L1Cache_State_to_permission(state));
        }
    }

    void functionalRead(Addr addr, Packet *pkt){
        TBE tbe := TBEs[addr];

        // see if it's undergoing changing
        if (is_valid(tbe)){
            testAndRead(addr, tbe.DataBlk, pkt);
        }
        else{
            testAndRead(addr, getCacheEntry(addr).DataBlk, pkt);
        }
    }

    int functionalWrite(Addr addr, Packet *pkt){
        TBE tbe := TBEs[addr];

        // see if it's undergoing changing
        if (is_valid(tbe)){
            if (testAndWrite(addr, tbe.DataBlk, pkt)){
                return 1;
            }
            else{
                return 0;
            }
        }
        else{
            if (testAndWrite(addr, getCacheEntry(addr).DataBlk, pkt)){
                return 1;
            }
            else{
                return 0;
            }
        }
    }

    /* Input/Output network */

    /*  Here first define the output port, which is the message buffer
        defined previously, I just rename the request to directory as 
        request out, and similarly for response;

        The msg will be defined in MSI-cache-msg.sm.
    */
    out_port(request_out, RequestMsg, requestToDir);
    out_port(response_out, ResponseMsg, responseToDirOrSibling);


    /*  Here following is the input port, which listed by the pirority for
        each input port block
    */

    in_port(response_in, ResponseMsg, responseFromDirOrSibling){
        // first check whether there is msg
        if (response_in.isReady(clockEdge())){

            // I fetch the msg
            peek(response_in, ResponseMsg){
                Entry cache_entry := getCacheEntry(in_msg.addr);
                TBE tbe := TBEs[in_msg.addr];

                assert(is_valid(tbe));          // as received response, then previously the entry must be passed to TBEs

                // firstly decide who is the sender of this response

                // from directory
                if (MachineIDToMachineType(in_msg.Sender) == MachineType::Directory){
                    if (in_msg.Type != CoherenceResponseType::Data){
                        error("Directory should only respond with Data type");
                    }

                    // the tbe AckOutstanding is the current acks we have received and the in_msg.acks is the acks directory ask us to wait for
                    assert(in_msg.Acks + tbe.AckOutstanding >= 0);

                    if (in_msg.Acks + tbe.AckOutstanding == 0){
                        trigger(Event:DataDirNoAcks, in_msg.addr, cache_entry, tbe);
                    }
                    else{
                        trigger(Event:DataDirAcks, in_msg.addr, cache_entry, tbe);
                    }
                }
                else{
                    if (in_msg.Type == CoherenceResponseType::Data){
                        trigger(Event:DataOwner, in_msg.addr, cache_entry, tbe);
                    }
                    else if (in_msg.Type == CoherenceResponseType::InvAck){
                        DPRINTF(RubySlicc, "Got inv ack. %d left\n", tbe.AckOutstanding);

                        if (tbe.AckOutstanding == 1){
                            trigger(Event::LastInvAck, in_msg.addr, cache_entry, tbe);
                        }
                        else{
                            trigger(Event:InvAck, in_msg.addr, cache_entry, tbe);
                        }
                    }
                    else{
                        error("Unexpected response from other cache");
                    }
                }
            }
        }
    }

    // the port for getting forward request from directory
    in_port(forward_in, RequestMsg, forwardFromDir){
        if (forward_in.isReady(clockEdge())){

            // I fetch the request msg
            peek(forward_in, RequestMsg){
                Entry cache_entry := getCacheEntry(in_msg.addr);
                TBE tbe := TBEs[in_msg.addr];

                // here is fwd-getS
                if (in_msg.Type == CoherenceRequestType:GetS){
                    trigger(Event:FwdGetS, in_msg.addr, cache_entry, tbe);
                }
                else if (in_msg.Type == CoherenceRequestType:GetM){
                    trigger(Event:FwdGetM, in_msg.addr, cache_entry, tbe)
                }
                else if (in_msg.Type == CoherenceRequestType:Inv){
                    trigger(Event:Inv, in_msg.addr, cache_entry, tbe);
                }
                else if (in_msg.Type == CoherenceRequestType:PutAck){
                    trigger(Event:PutAck, in_msg.addr, cache_entry, tbe);
                }
                else{
                    error("Unexpect forward request type");
                }
            }
        }
    }

    // the last and the lowest priority in port
    in_port(mandatory_in, RubyRequest, mandatoryQueue){
        if(mandatory_in.isReady(clockEdge())){

            // any ohter request on same line address will be blocked until the current is dealed
            peek(mandatory_in, RubyRequest, block_on = "LineAddress"){
                // refer to it by block-aligned addr
                Entry cache_entry := getCacheEntry(in_msg.LineAddress);
                TBE tbe := TBEs[in_msg.LineAddress];

                // the cache entry not in cache at all
                if (is_invalid(cache_entry) && cacheMemory.cacheAvail(in_msg.LineAddress) == false){

                    /* parameterized replacement policy */

                    Addr addr := cacheMemory.cacheProbe(in_msg.addr);
                    Entry victim_entry := getCacheEntry(addr);
                    TBE victim_tbe := TBEs[addr];
                    trigger(Event:Replacement, addr, victim_entry, victim_tbe);
                }
                else{
                    if (in_msg.Type == RubyRequestType:LD || in_msg.Type == RubyRequest:LFETCH){
                        trigger(Event:Load, in_msg.LineAddress, cache_entry, tbe);
                    }
                    else if (in_msg.Type == RubyRequestType:ST){
                        trigger(Event:Store, in_msg.LineAddress, cache_entry, tbe);
                    }
                    else{
                        error("Unexpected request type from processor");
                    }
                }

            }
        }
    }

    // action part 

    action(sendGetS, 'gS', desc="send GetS to directory"){
        // 1 is the cache latency, here is the miss in L1 cache
        enqueue(request_out, RequestMsg, 1){
            out_msg.addr := address;        // address is the value addr passed to trigger
            out_msg.Type := CoherenceRequestType:GetS;
            out_msg.Destination.add(mapAddressToMachine(address, MachineType:Directory));

            out_msg.Requestor := machineID;
            out_msg:MessageSize := MessageSizeType:Control;
        }
    }

    action(sendGetM, "gM", desc="send GetM to directory"){
        enqueue(request_out, RequestMsg, 1){
            out_msg.addr := address;
            out_msg.Type := CoherenceRequestType:GetM;
            out_msg.Destination.add(mapAddressToMachine(address, MachineType:Directory));

            out_msg.Requestor := machineID;
            out_msg:MessageSize := MessageSizeType:Control;
        }
    }

    action(sendPutS, "pS", desc="send PutS to directory"){
        enqueue(request_out, RequestMsg, 1){
            out_msg.addr := address;
            out_msg.Type := CoherenceRequestType:PutS;
            out_msg.Destination.add(mapAddressToMachine(address, MachineType:Directory));

            out_msg.Requestor := machineID;
            out_msg:MessageSize := MessageSizeType:Control;
        }
    }

    // since it's putM, we must give out the modified data
    action(sendPutM, "pM", desc="send PutM to directory"){
        enqueue(request_out, RequestMsg, 1){
            out_msg.addr := address;
            out_msg.Type := CoherenceRequestType:PutM;
            out_msg.Destination.add(mapAddressToMachine(address, MachineType:Directory));

            out_msg.Requestor := machineID;
            out_msg:MessageSize := MessageSizeType:Control;
            out_msg:DataBlk := cache_entry.DataBlk;
        }
    }

    action(sendDataToReq, "dR", desc="response to a forward request, it send data to the origin cache sending the request"){
        assert(is_valid(cache_entry));
        peek(forward_in, RequestMsg){
            enqueue(response_out, ResponseMsg, 1){
                out_msg.addr = address;
                out_msg.Type := CoherenceResponseType:Data;
                out_msg.Destination.add(in_msg.Requestor);

                out_msg.DataBlk := cache_entry.DataBlk;     // that's why I check before peek
                out_msg.MessageSize := MessageSizeType:Control;
                out_msg.Sender := machineID;
            }
        }
    }

    action(sendDataToDir, "dD", desc="response to a forward request, it send data to the sender directory"){
        assert(is_valid(cache_entry));
        enqueue(response_out, ResponseMsg, 1){
            out_msg.addr := address;
            out_msg.Type := CoherenceRequestType:Data;
            out_msg.Destination.add(mapAddressToMachine(address, MachineType:Directory));

            out_msg.Sender := machineID;
            out_msg:MessageSize := MessageSizeType:Control;
            out_msg:DataBlk := cache_entry.DataBlk;
        }
    }

    action(sendInvAck, "iaR", desc="send Inv ack to origin cache"){
        peek(forward_in, RequestMsg){
            enqueue(response_out, ResponseMsg, 1){
                out_msg.addr := address;
                out_msg.Type := CoherenceRequestType:InvAck;
                out_msg.Destination.add(in_msg.Requestor);

                out_msg.Sender := machineID;
                out_msg:MessageSize := MessageSizeType:Control;
                out_msg:DataBlk := cache_entry.DataBlk;
            }
        }
    }

    action(decrAck, "da", desc="decrease the number ack countings"){
        assert(is_valid(tbe));      // since we need to decrease tbe's AckOutstanding, so it must be valid
        tbe.AckOutstanding := tbe.AckOutstanding - 1;
        APPEND_TRANSITION_COMMENT("Acks: ");
        APPEND_TRANSITION_COMMENT(tbe.AckOutstanding);
    }

    action(storeAck, "sa", desc="store the return ack"){
        assert(is_valid(tbe));
        peek(response_in, ResponseMsg){
            tbe.AckOutstanding := in_msg.Acks + tbe.AckOutstanding;
        }
        assert(tbe.AckOutstanding > 0);
    }

    // action respond to CPU request

    assert(LoadHit, "Lh", desc="load hit"){
        assert(is_valid(cache_entry));
        cacheMemory.setMRU(cache_entry);
        sequencer.readCallBack(address, cache_entry.DataBlk, false);  // not miss
    }

    assert(externalLoadHit, "xLh", desc="external load hit( meeting a miss )"){
        assert(is_valid(cache_entry));
        peek(response_in, ResponseMsg){
            cacheMemory.setMRU(cache_entry);
            sequencer.readCallBack(in_msg.addr, cache_entry.DataBlk, true, MachineIDToMachineType(in_msg.Sender));
        }
    }

    assert(StoreHit, "Sh", desc="Store hit"){
        assert(is_valid(cache_entry));
        cacheMemory.setMRU(cache_entry);
        sequencer.writeCallBack(address, cache_entry.DataBlk, false);
    }

    assert(externalStoreHit, "eSh", desc="external store hit( meeting a miss)"){
        assert(is_valid(cache_entry));
        peek(response_in, ResponseMsg){
            cacheMemory.setMRU(cache_entry);
            sequencer.writeCallBack(in_msg.addr, cache_entry.DataBlk, true, MachineIDToMachineType(in_msg.Sender));
        }
    }

    assert(forwardEviction, "evict", desc="tell cpu the eviction of cache"){
        if (send_evictions){
            sequencer.evictionCallBack(address);
        }
    }

    // action of managing cache memory

    action(allocateCacheBlock, "a", desc="allocate a cache block"){
        // the ordered memory shouldn't be in cache
        assert(is_invalid(cache_entry));
        cacheMemory.cacheAvail(address);

        // now we allocate
        set_cache_entry(cacheMemory.allocate(address, new Entry));
    }

    action(deallocateCacheBlock, "d", desc="deallocate a cache block"){
        assert(is_valid(cache_entry));
        cacheMemory.deallocate(address);
        unset_cache_entry();
    }

    action(writeDataToCache, "wd", desc="write Data to the cache"){
        peek(response_in, ResponseMsg){
            assert(is_valid(cache_entry));
            cache_entry.DataBlk := in_msg.DataBlk;
        }
    }

    action(allocateTBE, "aT", desc="allocate a tbe"){
        assert(is_invalid(tbe));
        TBEs.allocate(address);
        set_tbe(TBEs.allocate(address));
    }

    action(deallocateTBE, "dT", desc="deallocate a tbe"){
        assert(is_valid(tbe));
        TBEs.deallocate(address);
        unset_tbe();
    }

    action(copyDataFromCacheToTBE, "DcT", desc="copy data from cache to tbe block"){
        assert(is_valid(tbe));
        assert(is_valid(cache_entry));
        tbe.DataBlk := cache_entry.DataBlk
    }

    action(popMandatoryQueue, "pQ", desc="pop message from mandatory_in"){
        mandatory_in.dequeue(clockEdge());
    }

    action(popResponseIn, "pR", desc="pop message from response queue"){
        response_in.dequeue(clockEdge());
    }

    action(popForwardIn, "pF", desc="pop message from forward queue"){
        forward_in.dequeue(clockEdge());
    }

    action(stall, "s", desc="stall incoming request"){
        // z_stall
    }

    // transition part

    transition(I, Load, IS_D){
        allocateCacheBlock;
        allocateTBE;
        sendGetS;
        popMandatoryQueue;
    }

    transition(IS_D, {Load, Store, Replacement, Inv}){
        stall;
    }

    transition(IS_D, {DataDirNoAcks, DataOwner}, S){
        writeDataToCache;
        deallocateTBE;
        externalStoreHit;
        popMandatoryQueue;
    }

    transition()
}